# Задача: ограничение max_tokens у агентов пака (снижение латентности)

**Дата:** 26.02.2026  
**Проект:** photo2sticker-bot  
**Статус:** Требования  
**Связано:** `docs/pack-multiagent-requirements.md`, `src/lib/pack-multiagent.ts`

---

## 1. Цель

Сократить время ответа пайплайна pack-агентов за счёт **жёсткого ограничения длины ответа** (`max_completion_tokens`) на каждом вызове OpenAI.  
По документации OpenAI: сокращение числа генерируемых токенов примерно на 50% даёт ~50% снижение латентности. Сейчас везде используется дефолт 4096 или 8192, при том что реальный объём ответа каждого агента — 200–800 токенов.

---

## 2. Текущее состояние

- В `openAiChatJson()` по умолчанию: `max_completion_tokens: options?.maxTokens ?? 4096`.
- Явно задано:
  - **Scenes** (первый проход): `maxTokens: 8192`
  - **Scenes** (rework): `maxTokens: 4096`
  - **Critic**: `maxTokens: 8192`
- **Concept, Boss, Captions** — без явного лимита → 4096.

Фактический объём ответов по контракту:

| Агент    | Выход (оценка токенов)     | Текущий лимит |
|----------|----------------------------|---------------|
| Concept  | ~200–400 (краткий JSON)    | 4096          |
| Boss     | ~400–800 (план + 9 моментов)| 4096         |
| Captions | ~100–200 (9 RU + 9 EN)     | 4096          |
| Scenes   | ~300–500 (9 предложений)   | 8192          |
| Critic   | ~150–300 (pass + 3+3 пунктов) | 8192      |

---

## 3. Требования

### 3.1. Ввести явный max_tokens на каждый вызов

Для каждого агента передавать в `openAiChatJson(..., { maxTokens: N })` значение **N** согласно таблице ниже. Значения подобраны с запасом (~1.5–2× от типичного объёма), чтобы не обрезать валидный ответ.

| Агент    | max_tokens | Обоснование |
|----------|------------|-------------|
| Concept  | 512        | Бриф: subject_type, setting, persona, tone, timeline, situation_types (3–5), shareability_hook, title_hint, visual_anchors. |
| Boss     | 1024       | План: id, name_ru/en, carousel_*, mood, segment_id, story_arc, tone, moments[9] (каждый 8–10 слов). |
| Captions | 512        | labels[9] + labels_en[9], по 15–20 символов — суммарно мало токенов. |
| Scenes   | 1024       | scene_descriptions[9], по 18–22 слова — ~250–400 токенов; запас на вариативность. |
| Critic   | 512        | pass + reasons[≤3] + suggestions[≤3], каждый пункт ≤20 слов. |

### 3.2. Места в коде для правок

- **Concept:** `runConcept()` — вызов `openAiChatJson(..., userMessage)` → добавить `{ maxTokens: 512 }`.
- **Boss:** `runBoss()` — добавить `{ maxTokens: 1024 }`.
- **Captions:** `runCaptions()` — добавить `{ maxTokens: 512 }`.
- **Scenes:** `runScenes()` — заменить `maxTokens: 8192` на `1024`.
- **Scenes (rework):** `runScenesForIndices()` / вызов из rework — использовать тот же лимит 1024 (или явно передать в `openAiChatJson` при вызове сцены по индексам).
- **Critic:** `runCritic()` — заменить `maxTokens: 8192` на `512`.

### 3.3. Константы (рекомендация)

Вынести лимиты в именованные константы в `pack-multiagent.ts`, чтобы не дублировать магические числа, например:

- `PACK_AGENT_MAX_TOKENS_CONCEPT = 512`
- `PACK_AGENT_MAX_TOKENS_BOSS = 1024`
- `PACK_AGENT_MAX_TOKENS_CAPTIONS = 512`
- `PACK_AGENT_MAX_TOKENS_SCENES = 1024`
- `PACK_AGENT_MAX_TOKENS_CRITIC = 512`

Использовать их во всех вызовах `openAiChatJson` для соответствующих агентов.

### 3.4. Обработка finish_reason = "length"

При жёстком лимите возможен ответ с `finish_reason: "length"` (модель упёрлась в лимит). Варианты:

- **Минимальный:** оставить текущую обработку (если парсинг JSON не удаётся или ответ обрезан — упадёт ошибка, пайплайн вернёт fail). При адекватных лимитах (512–1024) обрезка маловероятна.
- **Расширенный (по желанию):** при `finish_reason === "length"` логировать предупреждение и при необходимости увеличить лимит для этого агента в константах (после проверки на тестах).

В рамках данной задачи достаточно минимального варианта; при появлении обрезок — точечно поднять лимит по одному агенту.

---

## 4. Критерии приёмки

- [x] У каждого вызова OpenAI в пайплайне (Concept, Boss, Captions, Scenes, Critic, включая rework) задан явный `maxTokens` не больше указанного в п. 3.1.
- [x] Лимиты вынесены в константы (или явно заданы в одном месте), без магических чисел в теле вызовов.
- [x] Документация: в `docs/pack-multiagent-requirements.md` или `docs/pack-agent-prompts-final.md` добавлена краткая секция «Лимиты вывода (max_tokens)» с таблицей агент → max_tokens.
- [ ] После выката на тест: один-два прогона пайплайна без ошибок; при необходимости — проверить логи на `finish_reason: "length"` и при его появлении скорректировать лимит.

---

## 5. Ветка и коммиты

- Ветка: `feature/26-02-pack-agents-max-tokens-latency` (по правилу git-workflow: имя = имя документа без `.md`).
- Коммит: например `perf(pack): limit max_tokens per agent to reduce latency`.

---

## 6. Риски и откат

- **Риск:** слишком низкий лимит → обрезанный JSON → падение пайплайна.  
  **Митигация:** лимиты 512/1024 с запасом; при появлении обрезок — увеличить константу для конкретного агента.
- **Откат:** вернуть дефолт `options?.maxTokens ?? 4096` и убрать явные лимиты (или поднять константы до 4096/8192).
